# HF Agents Course Study Group: Bonus Units Review - July 12

> Notes are generated using Fathom

---
## Meeting Purpose

Discuss bonus units of an AI course and plan for future learning on MCP (Minimum Viable Product).

## Key Takeaways

  - Reviewed bonus units on function calling, agent observability/evaluation, and gaming applications
  - Planned to explore MCP course from Hugging Face in coming weeks
  - Participants shared updates on their progress and work-related AI initiatives

## Topics

### Function Calling Fine-Tuning

  - Fine-tuning LLMs for function calling improves their ability to trigger tools
  - Demonstrated example of fine-tuning Gamma 2b model on disaster tweet dataset (84% accuracy)
  - Discussed LORA (Low-Rank Adaptation) as an efficient fine-tuning technique
  - Explained process: define model, arguments, dataset, train, save, and make predictions

### Agent Observability and Evaluation

  - Tools like Langchain and OpenTelemetry help monitor agents in production
  - Features include conversation tracking, cost calculation, request errors, and user feedback
  - Automated evaluation matrices and LLM-as-judge concept introduced for response quality assessment
  - Dashboards available for visualizing agent performance metrics

### AI in Gaming

  - Briefly touched on LLM applications in gaming (e.g., NPC interactions)
  - Hugging Face space available for testing gaming agents

### MCP Course

  - New course by Hugging Face, complementary to current learning
  - Covers custom workflow servers, GitHub action integration, and Slack notifications
  - Practical focus with real-life use cases (e.g., building pull request agent)
  - Group expressed interest in starting this course in the coming weeks

## Next Steps

  - Share MCP course details with the group
  - Start MCP course on July 26th (tentative)
  - Ramya to join the Discord server for group communications
  - Pardeep to gauge interest and confirm MCP course plans in two weeks
